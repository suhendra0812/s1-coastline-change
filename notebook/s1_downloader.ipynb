{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from eodag import EODataAccessGateway, SearchResult\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "\n",
    "from big_tide_prediction import tide_interpolation, tide_prediction\n",
    "from coastline_change_functions import (\n",
    "    coregistration,\n",
    "    create_transects,\n",
    "    db_scale,\n",
    "    filter_tide,\n",
    "    intersection_percent,\n",
    "    lee_filter,\n",
    "    rescale,\n",
    "    segmentation,\n",
    "    smooth_linestring,\n",
    "    subpixel_contours,\n",
    "    transect_analysis,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "REGION_ID = 679\n",
    "START_DATE = \"2015-01-01\"\n",
    "STOP_DATE = \"2022-12-31\" # datetime.today().date().isoformat()\n",
    "TIDE_TYPE = \"mean\" # option: ht, lt, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_path = Path(\"../region/coastal_grids.geojson\")\n",
    "point_path = Path(\"../region/coastal_points.geojson\")\n",
    "\n",
    "region_gdf = gpd.read_file(region_path)\n",
    "point_gdf = gpd.read_file(point_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_region = region_gdf.query(\"province == 'BALI'\")\n",
    "# centroid = filter_region.unary_union.centroid\n",
    "\n",
    "# m = region_gdf.explore(\n",
    "#     location=[centroid.y, centroid.x],\n",
    "#     zoom_start=8,\n",
    "#     style_kwds={\"fillOpacity\": 0, \"color\": \"red\", \"linewidth\": 10},\n",
    "# )\n",
    "# for i, row in region_gdf.iterrows():\n",
    "#     centroid = row.geometry.centroid\n",
    "#     folium.Marker(\n",
    "#         location=[centroid.y, centroid.x],\n",
    "#         icon=folium.DivIcon(\n",
    "#             html=f'<div style=\"font-size: 12pt\">{i+1}</div>'\n",
    "#         )\n",
    "#     ).add_to(m)\n",
    "\n",
    "# folium.GeoJson(point_gdf.to_json()).add_to(m)\n",
    "\n",
    "# m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_region = region_gdf.loc[[REGION_ID-1]]\n",
    "selected_point = point_gdf.loc[[REGION_ID-1]]\n",
    "\n",
    "m = selected_region.explore(style_kwds={\"fillOpacity\": 0, \"color\": \"red\"})\n",
    "folium.GeoJson(selected_point.to_json()).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag = EODataAccessGateway()\n",
    "\n",
    "provider_path = Path(\n",
    "    \"/home/barata-serv/otomatisasi_barata/coastline/provider/sara_provider.yaml\"\n",
    ")\n",
    "\n",
    "with open(provider_path) as f:\n",
    "    dag.update_providers_config(f.read())\n",
    "\n",
    "dag.set_preferred_provider(\"sara\")\n",
    "logger.info(f\"Preferred provider: {dag.get_preferred_provider()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_region_geom = selected_region.unary_union\n",
    "\n",
    "search_params = {\n",
    "    \"productType\": \"S1_SAR_GRD\",\n",
    "    \"start\": START_DATE,\n",
    "    \"end\": STOP_DATE,\n",
    "    # \"geom\": {\"lonmin\": 114.573354951, \"lonmax\": 114.637952680, \"latmin\": -8.150957658, \"latmax\": -8.097021690},\n",
    "    \"geom\": selected_region_geom,\n",
    "}\n",
    "\n",
    "search_results = (\n",
    "    dag.search_all(**search_params)\n",
    "    .filter_property(polarizationMode=\"VH,VV\")\n",
    "    .filter_overlap(selected_region_geom, minimum_overlap=98)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_search_result_map(\n",
    "    search_results: SearchResult, extent: Polygon\n",
    ") -> folium.Map:\n",
    "    \"\"\"Small utility to create an interactive map with folium\n",
    "    that displays an extent in red and EO Producs in blue\"\"\"\n",
    "    result_gdf = gpd.GeoDataFrame.from_features(\n",
    "        search_results.as_geojson_object(), crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    fmap = result_gdf[\n",
    "        [\n",
    "            \"platform\",\n",
    "            \"orbitDirection\",\n",
    "            \"sensorMode\",\n",
    "            \"startTimeFromAscendingNode\",\n",
    "            \"polarizationMode\",\n",
    "            \"geometry\"\n",
    "        ]\n",
    "    ].explore(\n",
    "        location=[extent.centroid.y, extent.centroid.x],\n",
    "        zoom_start=8,\n",
    "        style_kwds=dict(color=\"blue\", fillOpacity=0, linewidth=1),\n",
    "    )\n",
    "\n",
    "    # folium.GeoJson(\n",
    "    #     search_results, style_function=lambda x: dict(fill=False, color=\"blue\")\n",
    "    # ).add_to(fmap)\n",
    "\n",
    "    folium.GeoJson(extent, style_function=lambda x: dict(color=\"red\")).add_to(fmap)\n",
    "    \n",
    "    return fmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_search_result_map(search_results, selected_region_geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = sorted(\n",
    "    [\n",
    "        pd.to_datetime(\n",
    "            result.properties[\"startTimeFromAscendingNode\"], utc=True\n",
    "        )\n",
    "        for result in search_results\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = selected_point.unary_union.centroid.x\n",
    "y = selected_point.unary_union.centroid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"../output\") / f\"{REGION_ID:04d}\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_path = output_dir / f'{REGION_ID:04d}_tide.csv'\n",
    "\n",
    "if not tide_path.exists():\n",
    "    start_date_data = time_list[0]\n",
    "    stop_date_data = time_list[-1]\n",
    "    tide_df = tide_prediction(x, y, start_date_data, stop_date_data)\n",
    "    interp_tide_df = tide_interpolation(tide_df, time_list)\n",
    "    interp_tide_df.reset_index(inplace=True)\n",
    "    interp_tide_df.rename(columns={\"index\": \"datetime\"}, inplace=True)\n",
    "    interp_tide_df.to_csv(tide_path, index=False)\n",
    "else:\n",
    "    interp_tide_df = pd.read_csv(tide_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_list = interp_tide_df['level'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = np.min(tide_list)\n",
    "ht = np.max(tide_list)\n",
    "mean = np.mean(tide_list)\n",
    "\n",
    "logger.info(f\"Low tide: {lt} | High tide: {ht} | Mean tide: {mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_results = []\n",
    "for result, tide in zip(search_results, tide_list):\n",
    "    result.properties[\"tide\"] = tide\n",
    "    tide_results.append(result)\n",
    "\n",
    "tide_results = SearchResult(sorted(tide_results, key=lambda x: x.properties[\"startTimeFromAscendingNode\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "grouped_results = [\n",
    "    SearchResult(group)\n",
    "    for _, group in groupby(\n",
    "        tide_results,\n",
    "        key=lambda x: parse(x.properties[\"startTimeFromAscendingNode\"]).year,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_results = SearchResult(\n",
    "    [\n",
    "        sorted(group, key=lambda x: abs(x.properties[\"tide\"] - lt))[0]\n",
    "        for group in grouped_results\n",
    "    ]\n",
    ")\n",
    "ht_results = SearchResult(\n",
    "    [\n",
    "        sorted(group, key=lambda x: abs(x.properties[\"tide\"] - ht))[0]\n",
    "        for group in grouped_results\n",
    "    ]\n",
    ")\n",
    "mean_results = SearchResult(\n",
    "    [\n",
    "        sorted(group, key=lambda x: abs(x.properties[\"tide\"] - mean))[0]\n",
    "        for group in grouped_results\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_s1_results_dict = {\n",
    "    \"ht\": ht_results,\n",
    "    \"lt\": lt_results,\n",
    "    \"mean\": mean_results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_results(results: SearchResult, base_dir: Path) -> None:\n",
    "    for result in results:\n",
    "        platform = result.properties[\"platform\"].lower()\n",
    "        product_type = result.properties[\"productType\"].lower()\n",
    "        sensor_mode = result.properties[\"sensorMode\"].lower()\n",
    "        sensing_time = parse(result.properties[\"startTimeFromAscendingNode\"])\n",
    "        year = sensing_time.year\n",
    "        month = sensing_time.month\n",
    "        day = sensing_time.day\n",
    "\n",
    "        output_dir = base_dir.joinpath(\n",
    "            platform,\n",
    "            f\"{platform}_{sensor_mode}_{product_type}\",\n",
    "            str(year),\n",
    "            f\"{month:02d}\",\n",
    "            f\"{day:02d}\",\n",
    "        )\n",
    "\n",
    "        dag.download(result, outputs_prefix=output_dir, extract=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_s1_results = tide_s1_results_dict[TIDE_TYPE]\n",
    "\n",
    "result_path = Path(\"../output\") / f\"{REGION_ID:04d}\" / f\"{REGION_ID:04d}_s1_{TIDE_TYPE}.geojson\"\n",
    "result_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "dag.serialize(tide_s1_results, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"/home/barata-serv/otomatisasi_barata/datasets/\")\n",
    "\n",
    "download_results(tide_s1_results, BASE_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b847be34aecb558b376b6ab85408bacbc974dcb60f21f7ac2ed6ffce76a82dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
