{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from datetime import date, datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import cv2\n",
    "import registration\n",
    "from dask.distributed import Client\n",
    "from dateutil.parser import parse\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import geopandas as gpd\n",
    "import httpx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import planetary_computer as pc\n",
    "from pystac import Item, ItemCollection\n",
    "import pystac_client\n",
    "from rioxarray.merge import merge_arrays\n",
    "from scipy import ndimage\n",
    "from shapely.geometry import mapping, shape, LineString, MultiLineString\n",
    "from skimage import filters, measure, morphology\n",
    "import stackstac\n",
    "import xarray as xr\n",
    "\n",
    "from coastline_change_functions import (\n",
    "    coregistration,\n",
    "    create_transects,\n",
    "    db_scale,\n",
    "    filter_tide,\n",
    "    intersection_percent,\n",
    "    lee_filter,\n",
    "    rescale,\n",
    "    segmentation,\n",
    "    smooth_linestring,\n",
    "    subpixel_contours,\n",
    "    tide_interpolation,\n",
    "    tide_prediction,\n",
    "    transect_analysis,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Path.home() / \"Development\" / \"coastline\")\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_URL = 'https://planetarycomputer.microsoft.com/api/stac/v1'\n",
    "COLLECTION = \"sentinel-1-rtc\"\n",
    "START_DATE = \"2015-01-01\"\n",
    "STOP_DATE = \"2022-12-31\"\n",
    "REGION_ID = 715\n",
    "TIDE_TYPE = \"mean\"\n",
    "MIN_AREA_PERCENT = 98 # percent\n",
    "COREGISTRATION = False\n",
    "THRESHOLD = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_client = Client(n_workers=4, threads_per_worker=2, memory_limit='4GB')\n",
    "dask_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_path = Path(\"./region/coastal_grids.geojson\")\n",
    "point_path = Path(\"./region/coastal_points.geojson\")\n",
    "\n",
    "region_gdf = gpd.read_file(region_path)\n",
    "point_gdf = gpd.read_file(point_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_region = region_gdf.query(\"province == 'BALI'\")\n",
    "# centroid = filter_region.unary_union.centroid\n",
    "\n",
    "# m = region_gdf.explore(\n",
    "#     location=[centroid.y, centroid.x],\n",
    "#     zoom_start=9,\n",
    "#     style_kwds={\"fillOpacity\": 0, \"color\": \"red\", \"linewidth\": 1}\n",
    "# )\n",
    "\n",
    "# for i, row in region_gdf.iterrows():\n",
    "#     centroid = row.geometry.centroid\n",
    "#     folium.Marker(\n",
    "#         location=[centroid.y, centroid.x],\n",
    "#         icon=folium.DivIcon(\n",
    "#             html=f\"<div style='font-size: 12px'>{i+1}</div>\"\n",
    "#         )\n",
    "#     ).add_to(m)\n",
    "\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_region_gdf = region_gdf.loc[[REGION_ID-1]]\n",
    "selected_point_gdf = point_gdf.loc[[REGION_ID-1]]\n",
    "\n",
    "m = selected_region_gdf.explore(style_kwds={\"fillOpacity\": 0, \"color\": \"red\"})\n",
    "m = selected_point_gdf.explore(m=m, marker_type=\"marker\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"./output\") / f\"{REGION_ID:04d}\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax = selected_region_gdf.total_bounds.tolist()\n",
    "bbox = xmin, ymin, xmax, ymax\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(CLIENT_URL)\n",
    "catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_list = []\n",
    "item_list = []\n",
    "\n",
    "start_date = parse(START_DATE)\n",
    "while start_date <= parse(STOP_DATE):\n",
    "    stop_date = start_date + relativedelta(years=1)\n",
    "    print(f\"Datetime search: {start_date} - {stop_date}\")\n",
    "\n",
    "    query = catalog.search(\n",
    "        collections=[COLLECTION],\n",
    "        datetime=[start_date, stop_date],\n",
    "        bbox=bbox,\n",
    "        query={\n",
    "            \"sar:polarizations\": {\"eq\": ['VV', 'VH']}\n",
    "        }\n",
    "    )\n",
    "    items = query.get_items()\n",
    "    for item in items:\n",
    "        area = intersection_percent(item, mapping(selected_region_gdf.unary_union))\n",
    "        if area >= MIN_AREA_PERCENT:\n",
    "            area_list.append(area)\n",
    "            item_list.append(item)\n",
    "        \n",
    "    start_date = stop_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = sorted(item_list, key=lambda x: x.datetime)\n",
    "s1_items = ItemCollection(item_list)\n",
    "print(f\"Found: {len(s1_items)} datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_item_gdf = gpd.GeoDataFrame.from_features(s1_items.to_dict(), crs=\"epsg:4326\")\n",
    "s1_item_gdf[\"area_percent\"] = area_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = sorted(pd.to_datetime(s1_item_gdf[\"datetime\"]))\n",
    "year_list = sorted(set(map(lambda x: x.year, time_list)))\n",
    "print(time_list[0], time_list[-1])\n",
    "print(year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = s1_item_gdf[[\"platform\", \"geometry\", \"datetime\", \"sat:absolute_orbit\", \"sat:orbit_state\", \"area_percent\"]].explore(\n",
    "    column=\"platform\", cmap=\"viridis\", style_kwds={\"fillOpacity\": 0}\n",
    ")\n",
    "\n",
    "m = selected_region_gdf.explore(m=m, style_kwds={\"fillOpacity\": 0.5, \"color\": \"red\"})\n",
    "m = selected_point_gdf.explore(m=m, marker_type=\"marker\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_s1_items = [pc.sign(item).to_dict() for item in s1_items]\n",
    "\n",
    "s1_data = (\n",
    "    stackstac.stack(\n",
    "        signed_s1_items,\n",
    "        bounds_latlon=bbox,\n",
    "        epsg=3857,\n",
    "        resolution=10,\n",
    "    )\n",
    "    .where(lambda x: x > 0, other=np.nan)\n",
    "    .sel(band=\"vh\")\n",
    ")\n",
    "s1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_query = catalog.search(\n",
    "    collections=[\"cop-dem-glo-30\"],\n",
    "    bbox=bbox\n",
    ")\n",
    "\n",
    "dem_items = dem_query.get_all_items()\n",
    "print(f\"Found: {len(dem_items):d} datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_item_gdf = gpd.GeoDataFrame.from_features(dem_items.to_dict(), crs=\"epsg:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = dem_item_gdf.explore(\n",
    "    style_kwds={\"fillOpacity\": 0}\n",
    ")\n",
    "\n",
    "m = selected_region_gdf.explore(m=m, style_kwds={\"fillOpacity\": 0.5, \"color\": \"red\"})\n",
    "m = selected_point_gdf.explore(m=m, marker_type=\"marker\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_dem_items = [pc.sign(item).to_dict() for item in dem_items]\n",
    "\n",
    "dem_data = (\n",
    "    stackstac.stack(\n",
    "        signed_dem_items,\n",
    "        bounds_latlon=bbox,\n",
    "        epsg=3857\n",
    "    )\n",
    "    # .where(lambda x: x > 0, other=np.nan)\n",
    "    .sel(band=\"data\")\n",
    "    .rio.write_nodata(0)\n",
    ")\n",
    "dem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dem_data = merge_arrays([dem for dem in dem_data.load()])\n",
    "merged_dem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = s1_data.time.values\n",
    "print(times[0], times[-1])\n",
    "\n",
    "x = selected_point_gdf.unary_union.centroid.x\n",
    "y = selected_point_gdf.unary_union.centroid.y\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_path = output_dir / f\"{REGION_ID:04d}_tide.csv\"\n",
    "\n",
    "if not tide_path.exists():\n",
    "    start_date = pd.to_datetime(times)[0].date()\n",
    "    stop_date = pd.to_datetime(times)[-1].date()\n",
    "    tide_df = tide_prediction(x, y, start_date, stop_date)\n",
    "    interp_tide_df = tide_interpolation(tide_df, pd.to_datetime(times).tolist())\n",
    "    interp_tide_df.to_csv(tide_path, index=False)\n",
    "else:\n",
    "    interp_tide_df = pd.read_csv(tide_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_list = interp_tide_df['level'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = np.min(tide_list)\n",
    "ht = np.max(tide_list)\n",
    "mean = np.mean(tide_list)\n",
    "\n",
    "print(f\"Low tide: {lt}\")\n",
    "print(f\"High tide: {ht}\")\n",
    "print(f\"Mean tide: {mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = interp_tide_df.plot(x=\"datetime\", y=\"level\", figsize=(10, 5))\n",
    "ax.axhline(y=lt, color=\"blue\", linestyle=\"dashed\", label=\"lt\")\n",
    "ax.axhline(y=mean, color=\"green\", linestyle=\"dashed\", label=\"mean\")\n",
    "ax.axhline(y=ht, color=\"red\", linestyle=\"dashed\", label=\"ht\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_data = xr.DataArray(tide_list, coords=[s1_data.time], dims=[\"time\"])\n",
    "tide_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_data[\"tide\"] = tide_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_s1_data = s1_data.groupby(\"time.year\")\n",
    "ht_s1_data = filter_tide(group_s1_data, ht)\n",
    "lt_s1_data = filter_tide(group_s1_data, lt)\n",
    "mean_s1_data = filter_tide(group_s1_data, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_s1_data_dict = {\n",
    "    \"ht\": ht_s1_data,\n",
    "    \"lt\": lt_s1_data,\n",
    "    \"mean\": mean_s1_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vh_data = tide_s1_data_dict[TIDE_TYPE].load()\n",
    "vh_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatake_ids = vh_data[\"s1:datatake_id\"].values\n",
    "datatake_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_filter_gdf = s1_item_gdf[s1_item_gdf[\"s1:datatake_id\"].isin(datatake_ids)]\n",
    "s1_filter_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = s1_filter_gdf[[\"platform\", \"geometry\", \"datetime\", \"sat:absolute_orbit\", \"sat:orbit_state\", \"area_percent\"]].explore(\n",
    "    column=\"datetime\", cmap=\"rainbow\", style_kwds={\"fillOpacity\": 0}\n",
    ")\n",
    "\n",
    "m = selected_region_gdf.explore(m=m, style_kwds={\"fillOpacity\": 0.5, \"color\": \"red\"})\n",
    "m = selected_point_gdf.explore(m=m, marker_type=\"marker\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COREGISTRATION:\n",
    "    new_vh_data = (\n",
    "        coregistration(vh_data)\n",
    "        .groupby(\"time\")\n",
    "        .apply(\n",
    "            lambda x: x\n",
    "            .rio.write_nodata(0)\n",
    "            .rio.interpolate_na()\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    new_vh_data = vh_data.copy()\n",
    "new_vh_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vh_data.plot(robust=True, cmap=\"gray\", col=\"time\", col_wrap=4, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vh_db_data = new_vh_data.groupby(\"time\").apply(db_scale)\n",
    "vh_db_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vh_db_data.plot(robust=True, cmap=\"gray\", col=\"time\", col_wrap=4, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vh_filter = (\n",
    "    vh_db_data\n",
    "    .groupby(\"time\")\n",
    "    .apply(lambda img: xr.apply_ufunc(\n",
    "            lee_filter,\n",
    "            img,\n",
    "            kwargs={\"size\": 5},\n",
    "            # dask=\"parallelized\",\n",
    "            # dask_gufunc_kwargs={\"allow_rechunk\": True}\n",
    "        )\n",
    "    )\n",
    ")\n",
    "vh_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vh_binary = (\n",
    "    vh_filter\n",
    "    .groupby(\"time\")\n",
    "    .apply(\n",
    "        lambda img: xr.apply_ufunc(\n",
    "            segmentation,\n",
    "            kwargs={\n",
    "                \"img\": img,\n",
    "                \"threshold\": THRESHOLD\n",
    "            }\n",
    "            # img.chunk({\"x\": -1, \"y\": -1}),\n",
    "            # dask=\"parallelized\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "vh_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_regrid = merged_dem_data.interp_like(vh_binary.isel(time=-1))\n",
    "dem_regrid = dem_regrid > 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vh_binary_filtered = (\n",
    "    vh_binary.groupby(\"time\")\n",
    "    .apply(lambda x: x.where(~dem_regrid, other=1))\n",
    ")\n",
    "vh_binary_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vh_binary_filtered.plot(cmap=\"gray\", col=\"time\", col_wrap=4, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastline_gdf = subpixel_contours(\n",
    "    vh_binary_filtered,\n",
    "    min_vertices=100,\n",
    "    crs=s1_data.crs,\n",
    "    affine=s1_data.transform\n",
    ")\n",
    "coastline_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lines = []\n",
    "for i, row in coastline_gdf.iterrows():\n",
    "    line = row.geometry\n",
    "    if line.geom_type == \"MultiLineString\":\n",
    "        new_line = MultiLineString([smooth_linestring(l, 5) for l in line.geoms])\n",
    "    else:\n",
    "        new_line = smooth_linestring(line, 5)\n",
    "    new_lines.append(new_line)\n",
    "    \n",
    "coastline_gdf.geometry = new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = coastline_gdf.geometry.iloc[0]\n",
    "transect_gdf = create_transects(baseline, 500, 100, crs=coastline_gdf.crs)\n",
    "transect_gdf.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transect_analysis_gdf = transect_analysis(coastline_gdf, transect_gdf, \"time\", reverse=True)\n",
    "transect_analysis_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastline_gdf[\"time\"] = coastline_gdf[\"time\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = coastline_gdf.explore(tiles=\"CartoDB dark_matter\", column=\"time\", cmap=\"Reds\")\n",
    "transect_analysis_gdf[[\"name\", \"mean_distance\", \"mean_change\", \"mean_rate\", \"geometry\"]].explore(m=m, column=\"mean_rate\", cmap=\"rainbow\", tiles=\"CartoDB dark_matter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suboutput_dir = output_dir / TIDE_TYPE\n",
    "suboutput_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastline_path = suboutput_dir / f\"{REGION_ID:04d}_s1_coastlines.geojson\"\n",
    "transect_path = suboutput_dir / f\"{REGION_ID:04d}_s1_transects.geojson\"\n",
    "transect_analysis_path = suboutput_dir / f\"{REGION_ID:04d}_s1_transect_analysis.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastline_gdf.to_file(coastline_path, driver=\"GeoJSON\")\n",
    "transect_gdf.to_file(transect_path, driver=\"GeoJSON\")\n",
    "transect_analysis_gdf.to_file(transect_analysis_path, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vh_db_coreg_rescale = (\n",
    "    vh_db_data.groupby(\"time\")\n",
    "    .apply(rescale, target_type_min=1, target_type_max=255, target_type=np.uint8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COREGISTRATION:\n",
    "    suffix = \"_coreg.tif\"\n",
    "else:\n",
    "    suffix = \".tif\"\n",
    "\n",
    "for time, d in vh_db_rescale.rename(\"vh_db\").groupby(\"time\"):\n",
    "    year = pd.to_datetime(time).year\n",
    "    raster_path = suboutput_dir / f\"{region_id:04d}_{year}_s1_vh_db{suffix}\"\n",
    "    d.rio.to_raster(raster_path, crs=s1_data.crs, compress=\"lzw\")\n",
    "    print(f\"Saved to {raster_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "4873c8c268bf5eb00eb5ac95872dc9e6410a710dfba70e424291da8bd96e2927"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
